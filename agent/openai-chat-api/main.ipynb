{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4aab8f1a",
   "metadata": {},
   "source": [
    "# Chapter02: Foundation of OpenAI's Chat API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cf72e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "loaded = load_dotenv()\n",
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f4d022",
   "metadata": {},
   "source": [
    "## 2.1 Use `tiktoken` to Count the Number of Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68db6cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "text = \"Can you tell me what should I do ?\"\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "tokens = encoding.encode(text)\n",
    "print(len(tokens))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85946c39",
   "metadata": {},
   "source": [
    "## 2.2 Simple Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64d978b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-BvgsHOT84gp9vaN4yMbTku8OqV8n6\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"Hello, Chen! How can I assist you today?\",\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"annotations\": []\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1753089205,\n",
      "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"service_tier\": \"default\",\n",
      "  \"system_fingerprint\": null,\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 11,\n",
      "    \"prompt_tokens\": 23,\n",
      "    \"total_tokens\": 34,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"reasoning_tokens\": 0,\n",
      "      \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": 0,\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello, I am Chen!\"}\n",
    "    ],\n",
    ")\n",
    "\n",
    "# `indent=2` means that each level of nesting is indented by two spaces.\n",
    "print(response.to_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441fdab1",
   "metadata": {},
   "source": [
    "### Obtain cline's response directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b09a81c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Chen! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "content = response.choices[0].message.content\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a358915",
   "metadata": {},
   "source": [
    "### OpenAI's ChatAPI is stateless. Hence, the conversation history is not saved, we need to include it with each request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5eba5af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-BvgSf7kbbfun7YlqNxlxAKq5FMFT3\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"Yes, you mentioned that your name is Chen. How can I help you, Chen?\",\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"annotations\": []\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1753087617,\n",
      "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"service_tier\": \"default\",\n",
      "  \"system_fingerprint\": null,\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 18,\n",
      "    \"prompt_tokens\": 50,\n",
      "    \"total_tokens\": 68,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"reasoning_tokens\": 0,\n",
      "      \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": 0,\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello, I am Chen!\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Hello, Chen! How can I assist you today?\"},\n",
    "        {\"role\": \"user\", \"content\": \"Do you know what my name is?\"}\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.to_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719e564a",
   "metadata": {},
   "source": [
    "## 2.3 Streaming Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fff29b",
   "metadata": {},
   "source": [
    "When using **streaming mode**, the model's response are split into individual chunks and the original `message` field becomes `delta`.\n",
    "\n",
    "This creates the effect of text appearing gradually, just like in a real-time conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63959850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Chen!  \n",
      "It's great to meet you.  \n",
      "Life is full of opportunities  \n",
      "and experiences waiting to be embraced.  \n",
      "Embrace each moment with joy  \n",
      "and curiosity, as they shape who you are.  \n",
      "Every encounter teaches a lesson,  \n",
      "and every challenge brings growth.  \n",
      "Keep exploring, learning, and shining brightly!"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello! I am Chen. Can you say something with 50 words? You should break a line when a sentence ends.\"},\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    content = chunk.choices[0].delta.content\n",
    "    if content is not None:\n",
    "        # `end=\"\"` overrides the default newline suffix (which is \"\\n\"), so nothing is appended after each `print` call.\n",
    "        # `flush=True` forces Python to immediately flush its output buffer to the terminal, \n",
    "        # ensuring each chunk is displayed right away rather than being buffered.\n",
    "        print(content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdbb973",
   "metadata": {},
   "source": [
    "## 2.4 Json Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4901c11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"people\": [\"Ben\", \"Jenny\", \"grandfather\", \"grandmother\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Please output the appeared persons in Json format. \\n{'people': ['aaa', 'bbb']}\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Ben is talking with Jenny. In the past, grandfather played chess with grandmother in a building.\"\n",
    "        },\n",
    "    ],\n",
    "    response_format={\"type\": \"json_object\"},\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800a7236",
   "metadata": {},
   "source": [
    "## 2.5 Image Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d87dcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "def jpg_to_data_uri(path: str) -> str:\n",
    "    '''\n",
    "    This function is used to convert *.jpg to urls which can be feed into GPT-4o.\n",
    "    '''\n",
    "    with open(path, \"rb\") as f:\n",
    "        b64 = base64.b64encode(f.read()).decode(\"ascii\")\n",
    "    return f\"data:image/jpeg;base64,{b64}\"\n",
    "\n",
    "image_path = \"example_img.jpeg\"\n",
    "image_uri = jpg_to_data_uri(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ef42f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image shows a table filled with various dishes, likely from an Asian cuisine. Visible on the table are:\n",
      "\n",
      "1. Grilled eggplant topped with sauce.\n",
      "2. Dishes of clams with sauce and vegetables.\n",
      "3. Grilled oysters with a savory topping.\n",
      "4. A plate of stir-fried noodles or shredded vegetables with chili.\n",
      "5. Skewers of grilled fish.\n",
      "6. Another plate of seafood with sauce.\n",
      "\n",
      "There's also a can of soda and some people partially visible in the background. The spread appears to be a mix of seafood and vegetable dishes.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"Please describe this image.\"},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": image_uri}}\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a0c41e",
   "metadata": {},
   "source": [
    "## 2.6 Function Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed03982",
   "metadata": {},
   "source": [
    "Functions need to be called locally.\n",
    "\n",
    "So we should send a request asking which functions should be utilized and call it locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50879cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    if \"tokyo\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": unit})\n",
    "    elif \"san francisco\" in location.lower():\n",
    "        return json.dumps({\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": unit})\n",
    "    elif \"paris\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": unit})\n",
    "    else:\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250779ac",
   "metadata": {},
   "source": [
    "**Prepare a tool list indicating GPT-4o the available funcions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "934a8c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\":{\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287987c6",
   "metadata": {},
   "source": [
    "**Now we know we should use the `get_current_weather` function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f643d2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-BvjnEx5SqpRAOVDyTZw5mUWcL20bp\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"tool_calls\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": null,\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"annotations\": [],\n",
      "        \"tool_calls\": [\n",
      "          {\n",
      "            \"id\": \"call_IkzO4U0syA3dU5noC8h5JJP1\",\n",
      "            \"function\": {\n",
      "              \"arguments\": \"{\\\"location\\\":\\\"Tokyo\\\"}\",\n",
      "              \"name\": \"get_current_weather\"\n",
      "            },\n",
      "            \"type\": \"function\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1753100424,\n",
      "  \"model\": \"gpt-4o-2024-08-06\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"service_tier\": \"default\",\n",
      "  \"system_fingerprint\": null,\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 15,\n",
      "    \"prompt_tokens\": 78,\n",
      "    \"total_tokens\": 93,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"reasoning_tokens\": 0,\n",
      "      \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": 0,\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"How about Tokyo's weather?\"},\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    ")\n",
    "print(response.to_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87790d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"How about Tokyo's weather?\"\n",
      "  },\n",
      "  {\n",
      "    \"content\": null,\n",
      "    \"refusal\": null,\n",
      "    \"role\": \"assistant\",\n",
      "    \"annotations\": [],\n",
      "    \"tool_calls\": [\n",
      "      {\n",
      "        \"id\": \"call_IkzO4U0syA3dU5noC8h5JJP1\",\n",
      "        \"function\": {\n",
      "          \"arguments\": \"{\\\"location\\\":\\\"Tokyo\\\"}\",\n",
      "          \"name\": \"get_current_weather\"\n",
      "        },\n",
      "        \"type\": \"function\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "response_message = response.choices[0].message\n",
    "messages.append(response_message.to_dict())\n",
    "print(json.dumps(messages, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7df6ba2",
   "metadata": {},
   "source": [
    "**Call the `get_current_weather` locally**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b977893e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"How about Tokyo's weather?\"\n",
      "  },\n",
      "  {\n",
      "    \"content\": null,\n",
      "    \"refusal\": null,\n",
      "    \"role\": \"assistant\",\n",
      "    \"annotations\": [],\n",
      "    \"tool_calls\": [\n",
      "      {\n",
      "        \"id\": \"call_IkzO4U0syA3dU5noC8h5JJP1\",\n",
      "        \"function\": {\n",
      "          \"arguments\": \"{\\\"location\\\":\\\"Tokyo\\\"}\",\n",
      "          \"name\": \"get_current_weather\"\n",
      "        },\n",
      "        \"type\": \"function\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"tool_call_id\": \"call_IkzO4U0syA3dU5noC8h5JJP1\",\n",
      "    \"role\": \"tool\",\n",
      "    \"name\": \"get_current_weather\",\n",
      "    \"content\": \"{\\\"location\\\": \\\"Tokyo\\\", \\\"temperature\\\": \\\"10\\\", \\\"unit\\\": null}\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "available_functions = {\n",
    "    \"get_current_weather\": get_current_weather\n",
    "}\n",
    "\n",
    "# Iterate over funcions that agent want to utilize\n",
    "for tool_call in response_message.tool_calls:\n",
    "    # Obtain the function name\n",
    "    function_name = tool_call.function.name\n",
    "    # Obtain the corresponding functhon object\n",
    "    function_to_call = available_functions[function_name]\n",
    "    # Load the parameters\n",
    "    function_args = json.loads(tool_call.function.arguments)\n",
    "    # Obtain and pass the parameters\n",
    "    function_response = function_to_call(\n",
    "        location=function_args.get(\"location\"),\n",
    "        unit=function_args.get(\"unit\"),\n",
    "    )\n",
    "\n",
    "    messages.append(\n",
    "        {\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"role\": \"tool\",\n",
    "            \"name\": function_name,\n",
    "            \"content\": function_response,\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(json.dumps(messages, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cd903139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-BvjnOaNOjTHvovcfNJScZuW2fti3v\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"The current temperature in Tokyo is 10 degrees.\",\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"annotations\": []\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1753100434,\n",
      "  \"model\": \"gpt-4o-2024-08-06\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"service_tier\": \"default\",\n",
      "  \"system_fingerprint\": \"fp_a288987b44\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 10,\n",
      "    \"prompt_tokens\": 54,\n",
      "    \"total_tokens\": 64,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"reasoning_tokens\": 0,\n",
      "      \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": 0,\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "-------------------------------------------------------\n",
      "The current temperature in Tokyo is 10 degrees.\n"
     ]
    }
   ],
   "source": [
    "second_response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages,\n",
    ")\n",
    "print(second_response.to_json(indent=2))\n",
    "print(\"-------------------------------------------------------\")\n",
    "print(second_response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-agent-py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
