{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b82b1568",
   "metadata": {},
   "source": [
    "# 第1章: 準備運動"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b540da",
   "metadata": {},
   "source": [
    "## 00. パタトクカシーー\n",
    "2つの文字列「パトカー」と「タクシー」の文字を先頭から交互に連結し、文字列「パタトクカシーー」を得よ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "254cbf2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "「パトカータクシー」\n"
     ]
    }
   ],
   "source": [
    "text1 = '「パトカー」'\n",
    "text2 = '「タクシー」'\n",
    "cat_text = text1[:-1] + text2[1:]\n",
    "print(cat_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38db282",
   "metadata": {},
   "source": [
    "## 01. タクシー\n",
    "文字列「パタトクカシーー」の2, 4, 6, 8文字目を取り出し、それらを連結した文字列を得よ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c533b5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パトカー\n"
     ]
    }
   ],
   "source": [
    "text = '「パタトクカシーー」'\n",
    "res = text[1] + text[3] + text[5] + text[7]\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4e327a",
   "metadata": {},
   "source": [
    "## 02. 文字列の逆順\n",
    "文字列”stressed”の文字を逆に（末尾から先頭に向かって）並べた文字列を得よ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dd71a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desserts\n"
     ]
    }
   ],
   "source": [
    "text = 'stressed'\n",
    "reversed_text = text[::-1]\n",
    "print(reversed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0cab03",
   "metadata": {},
   "source": [
    "## 03. 円周率\n",
    "“Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.”という文を単語に分解し、各単語の（アルファベットの）文字数を先頭から出現順に並べたリストを作成せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d1453e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5, 8, 9, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "text = 'Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.'\n",
    "\n",
    "# Remove all characters that are NOT letters, digits, underscores, or whitespace.\n",
    "text_only_words = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "# Convert words string to words list.\n",
    "text_only_words_list = text_only_words.split()\n",
    "\n",
    "# Obtain each word's length.\n",
    "lengths_list = [len(word) for word in text_only_words_list]\n",
    "print(lengths_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5f0daa",
   "metadata": {},
   "source": [
    "## 04. 元素記号\n",
    "“Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.”という文を単語に分解し、1, 5, 6, 7, 8, 9, 15, 16, 19番目の単語は先頭の1文字、それ以外の単語は先頭の2文字を取り出し、取り出した文字列から単語の位置（先頭から何番目の単語か）への連想配列（辞書型もしくはマップ型）を作成せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa1d412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Hi': 0, 'H': 1, 'Li': 2, 'Be': 3, 'Bo': 4, 'C': 19, 'N': 9, 'O': 7, 'F': 8, 'Na': 10, 'Mi': 11, 'Al': 12, 'Si': 13, 'Pe': 14, 'S': 15, 'Ar': 17, 'Ki': 18}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "text = 'Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.'\n",
    "text_only_words = re.sub(r'[^\\w\\s]', '', text)\n",
    "text_only_words_list = text_only_words.split()\n",
    "\n",
    "indices_first_characters = {1, 5, 6, 7, 8, 9, 15, 16, 19}\n",
    "\n",
    "res_dict = dict()\n",
    "for index, word in enumerate(text_only_words_list):\n",
    "    if index in indices_first_characters:\n",
    "        res_dict[word[0]] = index\n",
    "    else:\n",
    "        res_dict[word[:2]] = index\n",
    "\n",
    "print(res_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a8ba08",
   "metadata": {},
   "source": [
    "## 05. n-gram\n",
    "与えられたシーケンス（文字列やリストなど）からn-gramを作る関数を作成せよ。この関数を用い、”I am an NLPer”という文から文字tri-gram、単語bi-gramを得よ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11350fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I ', 'am', ' a', 'n ', 'NL', 'Pe', 'r[pad]']\n"
     ]
    }
   ],
   "source": [
    "def create_n_gram(sentence, n=2):\n",
    "    '''\n",
    "    sentence: raw sentence\n",
    "    n: n-gram\n",
    "    '''\n",
    "    res = []\n",
    "    length = len(sentence)\n",
    "    i = 0\n",
    "    while i < length:\n",
    "        # Pad the remaining substring with '[pad]' and append it\n",
    "        if i + n > length:\n",
    "            res.append(sentence[i:] + '[pad]' * (i + n - length))\n",
    "            break\n",
    "        res.append(sentence[i: i + n])\n",
    "        i += n\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "test_example = 'I am an NLPer'\n",
    "print(create_n_gram(test_example, n=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e856046",
   "metadata": {},
   "source": [
    "## 06.集合\n",
    "\n",
    "\"paraparaparadise\" と \"paragraph\" に含まれる文字 bi-gram の集合を、それぞれ **X** と **Y** として求め、  \n",
    "**X ∪ Y**（和集合）、**X ∩ Y**（積集合）、**X − Y**（差集合）を求めよ。  \n",
    "さらに、`'se'` という bi-gram が **X** および **Y** に含まれるかどうかを調べよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa302eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ra', 'pa', 'di', 'gr', 'ap', 'h[pad]', 'se'}\n",
      "{'ra', 'pa'}\n",
      "{'di', 'se'}\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "text_1 = 'paraparaparadise'\n",
    "text_2 = 'paragraph'\n",
    "text_1_bi_gram = set(create_n_gram(text_1))\n",
    "text_2_bi_gram = set(create_n_gram(text_2))\n",
    "\n",
    "union = text_1_bi_gram | text_2_bi_gram\n",
    "intersection = text_1_bi_gram & text_2_bi_gram\n",
    "difference = text_1_bi_gram - text_2_bi_gram\n",
    "\n",
    "include_X = 'se' in text_1_bi_gram\n",
    "include_Y = 'se' in text_2_bi_gram  \n",
    "\n",
    "print(union)\n",
    "print(intersection)\n",
    "print(difference)\n",
    "print(include_X)\n",
    "print(include_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37db841f",
   "metadata": {},
   "source": [
    "## 07. テンプレートによる文生成\n",
    "引数x, y, zを受け取り「x時のyはz」という文字列を返す関数を実装せよ。さらに、x=12, y=”気温”, z=22.4として、実行結果を確認せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b9760ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_template(x, y, z):\n",
    "    x, y, z = str(x), str(y), str(z)\n",
    "    res = '「' + x + '時の' + y + 'は' + z + '」'\n",
    "    return res\n",
    "\n",
    "x = 12\n",
    "y = '気温'\n",
    "z = 22.4\n",
    "\n",
    "res = create_template(x, y, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffe7d6c",
   "metadata": {},
   "source": [
    "## 08. 暗号文\n",
    "与えられた文字列の各文字を、以下の仕様で変換する関数`cipher`を実装せよ。\n",
    "\n",
    "- 英小文字ならば (219 - 文字コード) のASCIIコードに対応する文字に置換\n",
    "\n",
    "- その他の文字はそのまま出力\n",
    "\n",
    "この関数を用い、英語のメッセージを暗号化・復号化せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c84a3793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hzsz, glwzb rh z tllw wzb!\n",
      "Haha, today is a good day!\n"
     ]
    }
   ],
   "source": [
    "def cipher(string):\n",
    "    process_string = list(string)\n",
    "    for i, c in enumerate(process_string):\n",
    "        if 'a' <= c <= 'z':\n",
    "            process_string[i] = chr(219 - ord(c))\n",
    "    return ''.join(process_string)\n",
    "\n",
    "test_example = 'Haha, today is a good day!'\n",
    "test_example = cipher(test_example)     # Cipher\n",
    "print(test_example)\n",
    "test_example = cipher(test_example)     # Decipher\n",
    "print(test_example)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a74069",
   "metadata": {},
   "source": [
    "## 09. Typoglycemia\n",
    "スペースで区切られた単語列に対して、各単語の先頭と末尾の文字は残し、それ以外の文字の順序をランダムに並び替えるプログラムを作成せよ。ただし、長さが４以下の単語は並び替えないこととする。適当な英語の文（例えば”I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind .”）を与え、その実行結果を確認せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ff787db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I c'onudlt beelvie that I culod allcauty uenstandrd what I was reiandg : the pmnneheoal poewr of the hmuan mind .\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def random_position(word):\n",
    "    process_word = list(word)\n",
    "    middle = process_word[1: -1]\n",
    "    np.random.shuffle(middle)\n",
    "\n",
    "    return word[0] + ''.join(middle) + word[-1]\n",
    "\n",
    "\n",
    "def typoglycemia(string):\n",
    "    tokens = string.split() # Tokenization\n",
    "    \n",
    "    for i, token in enumerate(tokens):\n",
    "        if len(token) > 4:\n",
    "            tokens[i] = random_position(token)\n",
    "    res = ' '.join(tokens)\n",
    "    return res\n",
    "\n",
    "\n",
    "test = \"I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"\n",
    "print(typoglycemia(test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
