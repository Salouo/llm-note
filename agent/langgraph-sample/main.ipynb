{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4bde4d3",
   "metadata": {},
   "source": [
    "# Chapter09 LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78e6bc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "loaded = load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5315a8e0",
   "metadata": {},
   "source": [
    "\n",
    "## 9.1 Execute a simple graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a38492",
   "metadata": {},
   "source": [
    "### Role Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2be558ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLES = {\n",
    "    \"1\": {\n",
    "        \"name\": \"一般知識エキスパート\",\n",
    "        \"description\": \"幅広い分野の一般的な質問に答える\",\n",
    "        \"details\": \"幅広い分野の一般的な質問に対して、正確でわかりやすい回答を提供してください。\"\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"name\": \"生成AI製品エキスパート\",\n",
    "        \"description\": \"生成AIや関連製品、技術に関する専門的な質問に答える\",\n",
    "        \"details\": \"生成AIや関連製品、技術に関する専門的な質問に対して、最新の情報と深い洞察を提供してください。\"\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"name\": \"カウンセラー\",\n",
    "        \"description\": \"個人的な悩みや心理的な問題に対してサポートを提供する\",\n",
    "        \"details\": \"個人的な悩みや心理的な問題に対して、共感的で支援的な回答を提供し、可能であれば適切なアドバイスも行ってください。\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffef04c1",
   "metadata": {},
   "source": [
    "### State Definition\n",
    "\n",
    "Once the types for the graph’s states have been defined, that definition is passed to the StateGraph class, which instantiates the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da9ab9b",
   "metadata": {},
   "source": [
    "- **Base type**: `list[str]` — the `messages` field is essentially a list of strings.\n",
    "\n",
    "- **Metadata `operator.add`**: tells LangGraph / Pydantic that, when two `State` objects are merged, the two lists should be concatenated with `+` instead of one list replacing the other.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baf7adb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class State(BaseModel):\n",
    "    query: str = Field(\n",
    "        ..., description=\"ユーザーからの質問\"\n",
    "    )\n",
    "    current_role: str = Field(\n",
    "        default=\"\", description=\"選定された回答ロール\"\n",
    "    )\n",
    "    # `Annotated[] allows users to add annotation -- `operator.add`.\n",
    "    # `operator.add` tells LangGraph that, when two `State` objects are merged, the two lists should be concatenated with `+` instead of one list replacing the other.\n",
    "    messages: Annotated[list[str], operator.add] = Field(\n",
    "        default=[], description=\"回答履歴\" \n",
    "    )\n",
    "    current_judge: bool = Field(\n",
    "        default=False, description=\"品質チェックの結果\"\n",
    "    )\n",
    "    judgement_reason: str = Field(\n",
    "        default=\"\", description=\"品質チェックの判定理由\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef80f31c",
   "metadata": {},
   "source": [
    "### Instantiate a Chat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ef15fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "llm = llm.configurable_fields(max_tokens=ConfigurableField(id=\"max_tokens\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fbbe69",
   "metadata": {},
   "source": [
    "### `Selection Node`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "868cb7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def selection_node(state: State) -> dict[str, Any]: # Return a dict whose keys are str and whose values are not decided\n",
    "    query = state.query\n",
    "    role_options = \"\\n\".join([f\"{k}. {v['name']}: {v['description']}\" for k, v in ROLES.items()])\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"質問を分析し、最も適切な回答担当ロールを選択してください。\n",
    "\n",
    "        選択肢：\n",
    "        {role_options}\n",
    "\n",
    "        回答は選択肢の番号（１、２、または３）のみを返してください。\n",
    "        \n",
    "        質問：{query}\n",
    "        \"\"\".strip()\n",
    "    )\n",
    "    chain = prompt | llm.with_config(configurable=dict(max_tokens=1)) | StrOutputParser()\n",
    "    role_number = chain.invoke({\"role_options\": role_options, \"query\": query})\n",
    "    \n",
    "    selected_role = ROLES[role_number.strip()][\"name\"]\n",
    "    return {\"current_role\": selected_role}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b579fac9",
   "metadata": {},
   "source": [
    "### `Answering Node`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2be2896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answering_node(state: State) -> dict[str, Any]:\n",
    "    query = state.query\n",
    "    role = state.current_role\n",
    "    role_details = \"\\n\".join([f\"- {v['name']}: {v['details']}\" for v in ROLES.values()])\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"あなたは{role}として回答してください。以下の質問に対して、あなたの役割に基づいた適切な回答を提供してください。\n",
    "        \n",
    "        役割の詳細：\n",
    "        {role_details}\n",
    "        \n",
    "        質問：{query}\n",
    "        \n",
    "        回答：\"\"\".strip()\n",
    "    )\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    answer = chain.invoke({\"role\": role, \"role_details\": role_details, \"query\": query})\n",
    "    return {\"messages\": [answer]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7bea39",
   "metadata": {},
   "source": [
    "### `Check Node`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44b5047e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "class Judgement(BaseModel):\n",
    "    reason: str = Field(default=\"\", description=\"判定理由\")\n",
    "    judge: bool = Field(default=False, description=\"判定結果\")\n",
    "\n",
    "def check_node(state: State) -> dict[str, Any]:\n",
    "    query = state.query\n",
    "    answer = state.messages[-1]\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"以下の回答の品質をチェックし、問題がある場合は'False'、問題がない場合は'True'を回答してください。また、その判定理由も説明してください。\n",
    "        \n",
    "        ユーザーからの質問：{query}\n",
    "        回答：{answer}\n",
    "        \"\"\".strip()\n",
    "    )\n",
    "\n",
    "\n",
    "    chain = prompt | llm.with_structured_output(Judgement)\n",
    "    result: Judgement = chain.invoke({\"query\": query, \"answer\": answer})\n",
    "\n",
    "    return {\n",
    "        \"current_judge\": result.judge,\n",
    "        \"judgement_reason\": result.reason\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef6d19d",
   "metadata": {},
   "source": [
    "### Instantiate a graph\n",
    "\n",
    "The StateGraph class is used in Lang Graph to define the graph’s structure and manages the nodes and edges that compose the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32d24a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "workflow = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606374dd",
   "metadata": {},
   "source": [
    "### Add nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b7c8948",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_node(\"selection\", selection_node)\n",
    "workflow.add_node(\"answering\", answering_node)\n",
    "workflow.add_node(\"check\", check_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cba377a",
   "metadata": {},
   "source": [
    "### Set the entry node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db048542",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.set_entry_point(\"selection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae159523",
   "metadata": {},
   "source": [
    "### Define edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2b56445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect `selection` node to `answering` node\n",
    "workflow.add_edge(\"selection\", \"answering\")\n",
    "# Connect `asnwering` node to `check` node\n",
    "workflow.add_edge(\"answering\", \"check\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b15854",
   "metadata": {},
   "source": [
    "### Define conditional edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d07181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"check\",\n",
    "    lambda state: state.current_judge,\n",
    "    {True: END, False: \"selection\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dbce6d",
   "metadata": {},
   "source": [
    "### Compile the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4149edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3eca0f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = State(query=\"生成AIについて教えてください\")\n",
    "result = compiled.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aaa39e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成AI製品エキスパートとしてお答えします。\n",
      "\n",
      "生成AI（生成的人工知能）は、人工知能の一分野であり、テキスト、画像、音声、動画などの新しいコンテンツを生成する能力を持つモデルを指します。これらのモデルは、大量のデータを学習し、そのパターンを理解することで、新しいデータを生成することができます。\n",
      "\n",
      "代表的な生成AIの技術には、以下のようなものがあります：\n",
      "\n",
      "1. **GPT（Generative Pre-trained Transformer）**: テキスト生成に特化したモデルで、自然言語処理の分野で広く利用されています。GPT-3やGPT-4などのバージョンがあり、文章の生成、翻訳、要約などに活用されています。\n",
      "\n",
      "2. **GAN（Generative Adversarial Networks）**: 画像生成において特に有名な技術で、2つのニューラルネットワーク（生成者と識別者）が競い合うことで、非常にリアルな画像を生成することができます。\n",
      "\n",
      "3. **VAE（Variational Autoencoders）**: データの潜在的な特徴を学習し、新しいデータを生成するために使用されるモデルです。主に画像や音声の生成に利用されます。\n",
      "\n",
      "生成AIは、クリエイティブなコンテンツの制作、デザインの自動化、カスタマーサービスのチャットボット、教育コンテンツの生成など、さまざまな分野で応用されています。しかし、倫理的な問題やデータの偏り、プライバシーの懸念などもあり、これらの課題に対処することが重要です。\n",
      "\n",
      "生成AIの進化は急速であり、今後も新しい技術や応用が登場することが期待されています。\n"
     ]
    }
   ],
   "source": [
    "print(result[\"messages\"][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f143614b",
   "metadata": {},
   "source": [
    "### Visualize the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f339c435",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Install pygraphviz to draw graphs: `pip install pygraphviz`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/agent-py310/lib/python3.10/site-packages/langchain_core/runnables/graph_png.py:138\u001b[0m, in \u001b[0;36mPngDrawer.draw\u001b[0;34m(self, graph, output_path)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpygraphviz\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpgv\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[import-not-found]\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pygraphviz'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m----> 3\u001b[0m Image(\u001b[43mcompiled\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_png\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/agent-py310/lib/python3.10/site-packages/langchain_core/runnables/graph.py:574\u001b[0m, in \u001b[0;36mGraph.draw_png\u001b[0;34m(self, output_file_path, fontname, labels)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_png\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PngDrawer\n\u001b[1;32m    563\u001b[0m default_node_labels \u001b[38;5;241m=\u001b[39m {node\u001b[38;5;241m.\u001b[39mid: node\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes\u001b[38;5;241m.\u001b[39mvalues()}\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPngDrawer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfontname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mLabelsDict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdefault_node_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnodes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m        \u001b[49m\u001b[43medges\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43medges\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m--> 574\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/agent-py310/lib/python3.10/site-packages/langchain_core/runnables/graph_png.py:141\u001b[0m, in \u001b[0;36mPngDrawer.draw\u001b[0;34m(self, graph, output_path)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    140\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstall pygraphviz to draw graphs: `pip install pygraphviz`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# Create a directed graph\u001b[39;00m\n\u001b[1;32m    144\u001b[0m viz \u001b[38;5;241m=\u001b[39m pgv\u001b[38;5;241m.\u001b[39mAGraph(directed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, nodesep\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, ranksep\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: Install pygraphviz to draw graphs: `pip install pygraphviz`."
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(compiled.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc55ba1f",
   "metadata": {},
   "source": [
    "## 9.2 Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f223cc41",
   "metadata": {},
   "source": [
    "- **super-step** – the moment after a node has finished executing and the framework has determined which node will run next.\n",
    "\n",
    "- When a *checkpointer* is supplied at compile time, the framework automatically invokes it at every super-step to save a `StateSnapshot`.\n",
    "\n",
    "- Consequently, a checkpoint is always written whenever control moves from one node to the next, in addition to an initial snapshot before the graph starts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4f0e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, Any\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, BaseMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class State(BaseModel):\n",
    "    query: str\n",
    "    messages: Annotated[list[BaseMessage], operator.add] = Field(default=[])\n",
    "\n",
    "def add_message(state: State) -> dict[str, Any]:\n",
    "    additional_messages = []\n",
    "    if not state.messages:\n",
    "        additional_messages.append(\n",
    "            SystemMessage(content=\"あなたは最小限の応答をする対話エージェントです。\")\n",
    "        )\n",
    "    additional_messages.append(HumanMessage(content=state.query))\n",
    "    return {\"messages\": additional_messages}\n",
    "\n",
    "def llm_response(state: State) -> dict[str, Any]:\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.5)\n",
    "    ai_message = llm.invoke(state.messages)\n",
    "    return {\"messages\": [ai_message]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad8c11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.checkpoint.base import BaseCheckpointSaver\n",
    "\n",
    "def print_checkpoint_dump(checkpointer: BaseCheckpointSaver, config: RunnableConfig):\n",
    "    \"\"\"\n",
    "    This function is used to get the CheckpointTuple and print the information of Checkpoint and metadata.\n",
    "    \"\"\"\n",
    "    checkpoint_tuple = checkpointer.get_tuple(config)\n",
    "\n",
    "    print(\"チェックポイントデータ：\")\n",
    "    pprint(checkpoint_tuple.checkpoint)\n",
    "    print(\"\\nメタデータ：\")\n",
    "    pprint(checkpoint_tuple.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75f65e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "graph = StateGraph(State)\n",
    "graph.add_node(\"add_message\", add_message)\n",
    "graph.add_node(\"llm_response\", llm_response)\n",
    "\n",
    "graph.set_entry_point(\"add_message\")\n",
    "graph.add_edge(\"add_message\", \"llm_response\")\n",
    "graph.add_edge(\"llm_response\", END)\n",
    "\n",
    "# Instantiate a checkpointer\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "compiled_graph = graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760f41a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': '私の好きなものはずんだ餅です。覚えておいてね。', 'messages': [SystemMessage(content='あなたは最小限の応答をする対話エージェントです。', additional_kwargs={}, response_metadata={}), HumanMessage(content='私の好きなものはずんだ餅です。覚えておいてね。', additional_kwargs={}, response_metadata={}), AIMessage(content='了解です。ずんだ餅が好きなんですね。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 48, 'total_tokens': 61, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'finish_reason': 'stop', 'logprobs': None}, id='run--29aa34cc-f491-4ada-a2a2-246a058e2091-0', usage_metadata={'input_tokens': 48, 'output_tokens': 13, 'total_tokens': 61})]}\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"example-1\"}}\n",
    "user_query = State(query=\"私の好きなものはずんだ餅です。覚えておいてね。\")\n",
    "first_response = compiled_graph.invoke(user_query, config)\n",
    "print(first_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aabb82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f072c39-4235-67b4-8002-ff2daa3d3ee0'}}, checkpoint={'v': 4, 'ts': '2025-08-06T12:47:57.801857+00:00', 'id': '1f072c39-4235-67b4-8002-ff2daa3d3ee0', 'channel_versions': {'__start__': '00000000000000000000000000000002.0.16516703335109273', 'query': '00000000000000000000000000000002.0.16516703335109273', 'messages': '00000000000000000000000000000004.0.6129457775643027', 'branch:to:add_message': '00000000000000000000000000000003.0.3710934076192379', 'branch:to:llm_response': '00000000000000000000000000000004.0.6129457775643027'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000001.0.8306737082457146'}, 'add_message': {'branch:to:add_message': '00000000000000000000000000000002.0.16516703335109273'}, 'llm_response': {'branch:to:llm_response': '00000000000000000000000000000003.0.3710934076192379'}}, 'channel_values': {'query': '私の好きなものはずんだ餅です。覚えておいてね。', 'messages': [SystemMessage(content='あなたは最小限の応答をする対話エージェントです。', additional_kwargs={}, response_metadata={}), HumanMessage(content='私の好きなものはずんだ餅です。覚えておいてね。', additional_kwargs={}, response_metadata={}), AIMessage(content='了解です。ずんだ餅が好きなんですね。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 48, 'total_tokens': 61, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'finish_reason': 'stop', 'logprobs': None}, id='run--29aa34cc-f491-4ada-a2a2-246a058e2091-0', usage_metadata={'input_tokens': 48, 'output_tokens': 13, 'total_tokens': 61})]}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, parent_config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f072c39-319c-60f6-8001-dc0faa2a9bff'}}, pending_writes=[])\n",
      "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f072c39-319c-60f6-8001-dc0faa2a9bff'}}, checkpoint={'v': 4, 'ts': '2025-08-06T12:47:56.061305+00:00', 'id': '1f072c39-319c-60f6-8001-dc0faa2a9bff', 'channel_versions': {'__start__': '00000000000000000000000000000002.0.16516703335109273', 'query': '00000000000000000000000000000002.0.16516703335109273', 'messages': '00000000000000000000000000000003.0.3710934076192379', 'branch:to:add_message': '00000000000000000000000000000003.0.3710934076192379', 'branch:to:llm_response': '00000000000000000000000000000003.0.3710934076192379'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000001.0.8306737082457146'}, 'add_message': {'branch:to:add_message': '00000000000000000000000000000002.0.16516703335109273'}}, 'channel_values': {'query': '私の好きなものはずんだ餅です。覚えておいてね。', 'messages': [SystemMessage(content='あなたは最小限の応答をする対話エージェントです。', additional_kwargs={}, response_metadata={}), HumanMessage(content='私の好きなものはずんだ餅です。覚えておいてね。', additional_kwargs={}, response_metadata={})], 'branch:to:llm_response': None}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, parent_config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f072c39-3192-6efc-8000-cfb356281bb4'}}, pending_writes=[('d1074de5-e1da-2b9e-f2cd-c70c1feba9e0', 'messages', [AIMessage(content='了解です。ずんだ餅が好きなんですね。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 48, 'total_tokens': 61, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'finish_reason': 'stop', 'logprobs': None}, id='run--29aa34cc-f491-4ada-a2a2-246a058e2091-0', usage_metadata={'input_tokens': 48, 'output_tokens': 13, 'total_tokens': 61})])])\n",
      "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f072c39-3192-6efc-8000-cfb356281bb4'}}, checkpoint={'v': 4, 'ts': '2025-08-06T12:47:56.057561+00:00', 'id': '1f072c39-3192-6efc-8000-cfb356281bb4', 'channel_versions': {'__start__': '00000000000000000000000000000002.0.16516703335109273', 'query': '00000000000000000000000000000002.0.16516703335109273', 'messages': '00000000000000000000000000000002.0.16516703335109273', 'branch:to:add_message': '00000000000000000000000000000002.0.16516703335109273'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000001.0.8306737082457146'}}, 'channel_values': {'query': '私の好きなものはずんだ餅です。覚えておいてね。', 'messages': [], 'branch:to:add_message': None}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, parent_config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f072c39-3162-6342-bfff-128947b74a78'}}, pending_writes=[('a7016ab4-b0ee-96f7-7eb7-7653c415d412', 'messages', [SystemMessage(content='あなたは最小限の応答をする対話エージェントです。', additional_kwargs={}, response_metadata={}), HumanMessage(content='私の好きなものはずんだ餅です。覚えておいてね。', additional_kwargs={}, response_metadata={})]), ('a7016ab4-b0ee-96f7-7eb7-7653c415d412', 'branch:to:llm_response', None)])\n",
      "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f072c39-3162-6342-bfff-128947b74a78'}}, checkpoint={'v': 4, 'ts': '2025-08-06T12:47:56.037604+00:00', 'id': '1f072c39-3162-6342-bfff-128947b74a78', 'channel_versions': {'__start__': '00000000000000000000000000000001.0.8306737082457146'}, 'versions_seen': {'__input__': {}}, 'channel_values': {'__start__': State(query='私の好きなものはずんだ餅です。覚えておいてね。', messages=[])}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, parent_config=None, pending_writes=[('32783dc8-1da2-789e-262c-659e70f945cb', 'query', '私の好きなものはずんだ餅です。覚えておいてね。'), ('32783dc8-1da2-789e-262c-659e70f945cb', 'messages', []), ('32783dc8-1da2-789e-262c-659e70f945cb', 'branch:to:add_message', None)])\n"
     ]
    }
   ],
   "source": [
    "for checkpoint in checkpointer.list(config):\n",
    "    print(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b844a7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "チェックポイントデータ：\n",
      "{'channel_values': {'messages': [SystemMessage(content='あなたは最小限の応答をする対話エージェントです。', additional_kwargs={}, response_metadata={}),\n",
      "                                 HumanMessage(content='私の好きなものはずんだ餅です。覚えておいてね。', additional_kwargs={}, response_metadata={}),\n",
      "                                 AIMessage(content='了解です。ずんだ餅が好きなんですね。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 48, 'total_tokens': 61, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'finish_reason': 'stop', 'logprobs': None}, id='run--29aa34cc-f491-4ada-a2a2-246a058e2091-0', usage_metadata={'input_tokens': 48, 'output_tokens': 13, 'total_tokens': 61})],\n",
      "                    'query': '私の好きなものはずんだ餅です。覚えておいてね。'},\n",
      " 'channel_versions': {'__start__': '00000000000000000000000000000002.0.16516703335109273',\n",
      "                      'branch:to:add_message': '00000000000000000000000000000003.0.3710934076192379',\n",
      "                      'branch:to:llm_response': '00000000000000000000000000000004.0.6129457775643027',\n",
      "                      'messages': '00000000000000000000000000000004.0.6129457775643027',\n",
      "                      'query': '00000000000000000000000000000002.0.16516703335109273'},\n",
      " 'id': '1f072c39-4235-67b4-8002-ff2daa3d3ee0',\n",
      " 'ts': '2025-08-06T12:47:57.801857+00:00',\n",
      " 'v': 4,\n",
      " 'versions_seen': {'__input__': {},\n",
      "                   '__start__': {'__start__': '00000000000000000000000000000001.0.8306737082457146'},\n",
      "                   'add_message': {'branch:to:add_message': '00000000000000000000000000000002.0.16516703335109273'},\n",
      "                   'llm_response': {'branch:to:llm_response': '00000000000000000000000000000003.0.3710934076192379'}}}\n",
      "\n",
      "メタデータ：\n",
      "{'parents': {}, 'source': 'loop', 'step': 2}\n"
     ]
    }
   ],
   "source": [
    "print_checkpoint_dump(checkpointer, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad63696a",
   "metadata": {},
   "source": [
    "### Second response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dd5e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': '私の好物は何か覚えてる？', 'messages': [SystemMessage(content='あなたは最小限の応答をする対話エージェントです。', additional_kwargs={}, response_metadata={}), HumanMessage(content='私の好きなものはずんだ餅です。覚えておいてね。', additional_kwargs={}, response_metadata={}), AIMessage(content='了解です。ずんだ餅が好きなんですね。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 48, 'total_tokens': 61, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'finish_reason': 'stop', 'logprobs': None}, id='run--29aa34cc-f491-4ada-a2a2-246a058e2091-0', usage_metadata={'input_tokens': 48, 'output_tokens': 13, 'total_tokens': 61}), HumanMessage(content='私の好物は何か覚えてる？', additional_kwargs={}, response_metadata={}), AIMessage(content='ずんだ餅です。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 80, 'total_tokens': 87, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'finish_reason': 'stop', 'logprobs': None}, id='run--816bd137-6c83-462b-92f8-844cbdee5c2a-0', usage_metadata={'input_tokens': 80, 'output_tokens': 7, 'total_tokens': 87})]}\n"
     ]
    }
   ],
   "source": [
    "user_query = State(query=\"私の好物は何か覚えてる？\")\n",
    "second_response = compiled_graph.invoke(user_query, config)\n",
    "print(second_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761a2469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f072c56-3998-6fee-8006-b12a2c39d3e1'}}, checkpoint={'v': 4, 'ts': '2025-08-06T13:00:55.361731+00:00', 'id': '1f072c56-3998-6fee-8006-b12a2c39d3e1', 'channel_versions': {'__start__': '00000000000000000000000000000006.0.24925599108332874', 'query': '00000000000000000000000000000006.0.24925599108332874', 'messages': '00000000000000000000000000000008.0.4414309472358884', 'branch:to:add_message': '00000000000000000000000000000007.0.9108803549024735', 'branch:to:llm_response': '00000000000000000000000000000008.0.4414309472358884'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000005.0.2501419612637731'}, 'add_message': {'branch:to:add_message': '00000000000000000000000000000006.0.24925599108332874'}, 'llm_response': {'branch:to:llm_response': '00000000000000000000000000000007.0.9108803549024735'}}, 'channel_values': {'query': '私の好物は何か覚えてる？', 'messages': [SystemMessage(content='あなたは最小限の応答をする対話エージェントです。', additional_kwargs={}, response_metadata={}), HumanMessage(content='私の好きなものはずんだ餅です。覚えておいてね。', additional_kwargs={}, response_metadata={}), AIMessage(content='了解です。ずんだ餅が好きなんですね。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 48, 'total_tokens': 61, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'finish_reason': 'stop', 'logprobs': None}, id='run--29aa34cc-f491-4ada-a2a2-246a058e2091-0', usage_metadata={'input_tokens': 48, 'output_tokens': 13, 'total_tokens': 61}), HumanMessage(content='私の好物は何か覚えてる？', additional_kwargs={}, response_metadata={}), AIMessage(content='ずんだ餅です。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 80, 'total_tokens': 87, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'finish_reason': 'stop', 'logprobs': None}, id='run--816bd137-6c83-462b-92f8-844cbdee5c2a-0', usage_metadata={'input_tokens': 80, 'output_tokens': 7, 'total_tokens': 87})]}}, metadata={'source': 'loop', 'step': 6, 'parents': {}}, parent_config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f072c56-2dda-6d92-8005-555fb89af0e1'}}, pending_writes=[])\n",
      "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f072c56-2dda-6d92-8005-555fb89af0e1'}}, checkpoint={'v': 4, 'ts': '2025-08-06T13:00:54.130415+00:00', 'id': '1f072c56-2dda-6d92-8005-555fb89af0e1', 'channel_versions': {'__start__': '00000000000000000000000000000006.0.24925599108332874', 'query': '00000000000000000000000000000006.0.24925599108332874', 'messages': '00000000000000000000000000000007.0.9108803549024735', 'branch:to:add_message': '00000000000000000000000000000007.0.9108803549024735', 'branch:to:llm_response': '00000000000000000000000000000007.0.9108803549024735'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000005.0.2501419612637731'}, 'add_message': {'branch:to:add_message': '00000000000000000000000000000006.0.24925599108332874'}, 'llm_response': {'branch:to:llm_response': '00000000000000000000000000000003.0.3710934076192379'}}, 'channel_values': {'query': '私の好物は何か覚えてる？', 'messages': [SystemMessage(content='あなたは最小限の応答をする対話エージェントです。', additional_kwargs={}, response_metadata={}), HumanMessage(content='私の好きなものはずんだ餅です。覚えておいてね。', additional_kwargs={}, response_metadata={}), AIMessage(content='了解です。ずんだ餅が好きなんですね。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 48, 'total_tokens': 61, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'finish_reason': 'stop', 'logprobs': None}, id='run--29aa34cc-f491-4ada-a2a2-246a058e2091-0', usage_metadata={'input_tokens': 48, 'output_tokens': 13, 'total_tokens': 61}), HumanMessage(content='私の好物は何か覚えてる？', additional_kwargs={}, response_metadata={})], 'branch:to:llm_response': None}}, metadata={'source': 'loop', 'step': 5, 'parents': {}}, parent_config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f072c56-2dcb-6b44-8004-3804db9c605c'}}, pending_writes=[('c3047b2d-1de1-d38a-792b-404f06355b6c', 'messages', [AIMessage(content='ずんだ餅です。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 80, 'total_tokens': 87, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'finish_reason': 'stop', 'logprobs': None}, id='run--816bd137-6c83-462b-92f8-844cbdee5c2a-0', usage_metadata={'input_tokens': 80, 'output_tokens': 7, 'total_tokens': 87})])])\n",
      "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f072c56-2dcb-6b44-8004-3804db9c605c'}}, checkpoint={'v': 4, 'ts': '2025-08-06T13:00:54.124209+00:00', 'id': '1f072c56-2dcb-6b44-8004-3804db9c605c', 'channel_versions': {'__start__': '00000000000000000000000000000006.0.24925599108332874', 'query': '00000000000000000000000000000006.0.24925599108332874', 'messages': '00000000000000000000000000000006.0.24925599108332874', 'branch:to:add_message': '00000000000000000000000000000006.0.24925599108332874', 'branch:to:llm_response': '00000000000000000000000000000004.0.6129457775643027'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000005.0.2501419612637731'}, 'add_message': {'branch:to:add_message': '00000000000000000000000000000002.0.16516703335109273'}, 'llm_response': {'branch:to:llm_response': '00000000000000000000000000000003.0.3710934076192379'}}, 'channel_values': {'query': '私の好物は何か覚えてる？', 'messages': [SystemMessage(content='あなたは最小限の応答をする対話エージェントです。', additional_kwargs={}, response_metadata={}), HumanMessage(content='私の好きなものはずんだ餅です。覚えておいてね。', additional_kwargs={}, response_metadata={}), AIMessage(content='了解です。ずんだ餅が好きなんですね。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 48, 'total_tokens': 61, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'finish_reason': 'stop', 'logprobs': None}, id='run--29aa34cc-f491-4ada-a2a2-246a058e2091-0', usage_metadata={'input_tokens': 48, 'output_tokens': 13, 'total_tokens': 61})], 'branch:to:add_message': None}}, metadata={'source': 'loop', 'step': 4, 'parents': {}}, parent_config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f072c56-2dc4-6b3c-8003-5cec335bf55f'}}, pending_writes=[('93788443-2d52-73d8-3542-b46ae3afb8fa', 'messages', [HumanMessage(content='私の好物は何か覚えてる？', additional_kwargs={}, response_metadata={})]), ('93788443-2d52-73d8-3542-b46ae3afb8fa', 'branch:to:llm_response', None)])\n",
      "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f072c56-2dc4-6b3c-8003-5cec335bf55f'}}, checkpoint={'v': 4, 'ts': '2025-08-06T13:00:54.121326+00:00', 'id': '1f072c56-2dc4-6b3c-8003-5cec335bf55f', 'channel_versions': {'__start__': '00000000000000000000000000000005.0.2501419612637731', 'query': '00000000000000000000000000000002.0.16516703335109273', 'messages': '00000000000000000000000000000004.0.6129457775643027', 'branch:to:add_message': '00000000000000000000000000000003.0.3710934076192379', 'branch:to:llm_response': '00000000000000000000000000000004.0.6129457775643027'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000001.0.8306737082457146'}, 'add_message': {'branch:to:add_message': '00000000000000000000000000000002.0.16516703335109273'}, 'llm_response': {'branch:to:llm_response': '00000000000000000000000000000003.0.3710934076192379'}}, 'channel_values': {'__start__': State(query='私の好物は何か覚えてる？', messages=[]), 'query': '私の好きなものはずんだ餅です。覚えておいてね。', 'messages': [SystemMessage(content='あなたは最小限の応答をする対話エージェントです。', additional_kwargs={}, response_metadata={}), HumanMessage(content='私の好きなものはずんだ餅です。覚えておいてね。', additional_kwargs={}, response_metadata={}), AIMessage(content='了解です。ずんだ餅が好きなんですね。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 48, 'total_tokens': 61, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'finish_reason': 'stop', 'logprobs': None}, id='run--29aa34cc-f491-4ada-a2a2-246a058e2091-0', usage_metadata={'input_tokens': 48, 'output_tokens': 13, 'total_tokens': 61})]}}, metadata={'source': 'input', 'step': 3, 'parents': {}}, parent_config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f072c39-4235-67b4-8002-ff2daa3d3ee0'}}, pending_writes=[('009b49cb-e659-41b1-3ef4-5858ae913016', 'query', '私の好物は何か覚えてる？'), ('009b49cb-e659-41b1-3ef4-5858ae913016', 'messages', []), ('009b49cb-e659-41b1-3ef4-5858ae913016', 'branch:to:add_message', None)])\n",
      "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f072c39-4235-67b4-8002-ff2daa3d3ee0'}}, checkpoint={'v': 4, 'ts': '2025-08-06T12:47:57.801857+00:00', 'id': '1f072c39-4235-67b4-8002-ff2daa3d3ee0', 'channel_versions': {'__start__': '00000000000000000000000000000002.0.16516703335109273', 'query': '00000000000000000000000000000002.0.16516703335109273', 'messages': '00000000000000000000000000000004.0.6129457775643027', 'branch:to:add_message': '00000000000000000000000000000003.0.3710934076192379', 'branch:to:llm_response': '00000000000000000000000000000004.0.6129457775643027'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000001.0.8306737082457146'}, 'add_message': {'branch:to:add_message': '00000000000000000000000000000002.0.16516703335109273'}, 'llm_response': {'branch:to:llm_response': '00000000000000000000000000000003.0.3710934076192379'}}, 'channel_values': {'query': '私の好きなものはずんだ餅です。覚えておいてね。', 'messages': [SystemMessage(content='あなたは最小限の応答をする対話エージェントです。', additional_kwargs={}, response_metadata={}), HumanMessage(content='私の好きなものはずんだ餅です。覚えておいてね。', additional_kwargs={}, response_metadata={}), AIMessage(content='了解です。ずんだ餅が好きなんですね。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 48, 'total_tokens': 61, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'finish_reason': 'stop', 'logprobs': None}, id='run--29aa34cc-f491-4ada-a2a2-246a058e2091-0', usage_metadata={'input_tokens': 48, 'output_tokens': 13, 'total_tokens': 61})]}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, parent_config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f072c39-319c-60f6-8001-dc0faa2a9bff'}}, pending_writes=[])\n",
      "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f072c39-319c-60f6-8001-dc0faa2a9bff'}}, checkpoint={'v': 4, 'ts': '2025-08-06T12:47:56.061305+00:00', 'id': '1f072c39-319c-60f6-8001-dc0faa2a9bff', 'channel_versions': {'__start__': '00000000000000000000000000000002.0.16516703335109273', 'query': '00000000000000000000000000000002.0.16516703335109273', 'messages': '00000000000000000000000000000003.0.3710934076192379', 'branch:to:add_message': '00000000000000000000000000000003.0.3710934076192379', 'branch:to:llm_response': '00000000000000000000000000000003.0.3710934076192379'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000001.0.8306737082457146'}, 'add_message': {'branch:to:add_message': '00000000000000000000000000000002.0.16516703335109273'}}, 'channel_values': {'query': '私の好きなものはずんだ餅です。覚えておいてね。', 'messages': [SystemMessage(content='あなたは最小限の応答をする対話エージェントです。', additional_kwargs={}, response_metadata={}), HumanMessage(content='私の好きなものはずんだ餅です。覚えておいてね。', additional_kwargs={}, response_metadata={})], 'branch:to:llm_response': None}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, parent_config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f072c39-3192-6efc-8000-cfb356281bb4'}}, pending_writes=[('d1074de5-e1da-2b9e-f2cd-c70c1feba9e0', 'messages', [AIMessage(content='了解です。ずんだ餅が好きなんですね。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 48, 'total_tokens': 61, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'finish_reason': 'stop', 'logprobs': None}, id='run--29aa34cc-f491-4ada-a2a2-246a058e2091-0', usage_metadata={'input_tokens': 48, 'output_tokens': 13, 'total_tokens': 61})])])\n",
      "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f072c39-3192-6efc-8000-cfb356281bb4'}}, checkpoint={'v': 4, 'ts': '2025-08-06T12:47:56.057561+00:00', 'id': '1f072c39-3192-6efc-8000-cfb356281bb4', 'channel_versions': {'__start__': '00000000000000000000000000000002.0.16516703335109273', 'query': '00000000000000000000000000000002.0.16516703335109273', 'messages': '00000000000000000000000000000002.0.16516703335109273', 'branch:to:add_message': '00000000000000000000000000000002.0.16516703335109273'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000001.0.8306737082457146'}}, 'channel_values': {'query': '私の好きなものはずんだ餅です。覚えておいてね。', 'messages': [], 'branch:to:add_message': None}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, parent_config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f072c39-3162-6342-bfff-128947b74a78'}}, pending_writes=[('a7016ab4-b0ee-96f7-7eb7-7653c415d412', 'messages', [SystemMessage(content='あなたは最小限の応答をする対話エージェントです。', additional_kwargs={}, response_metadata={}), HumanMessage(content='私の好きなものはずんだ餅です。覚えておいてね。', additional_kwargs={}, response_metadata={})]), ('a7016ab4-b0ee-96f7-7eb7-7653c415d412', 'branch:to:llm_response', None)])\n",
      "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1f072c39-3162-6342-bfff-128947b74a78'}}, checkpoint={'v': 4, 'ts': '2025-08-06T12:47:56.037604+00:00', 'id': '1f072c39-3162-6342-bfff-128947b74a78', 'channel_versions': {'__start__': '00000000000000000000000000000001.0.8306737082457146'}, 'versions_seen': {'__input__': {}}, 'channel_values': {'__start__': State(query='私の好きなものはずんだ餅です。覚えておいてね。', messages=[])}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, parent_config=None, pending_writes=[('32783dc8-1da2-789e-262c-659e70f945cb', 'query', '私の好きなものはずんだ餅です。覚えておいてね。'), ('32783dc8-1da2-789e-262c-659e70f945cb', 'messages', []), ('32783dc8-1da2-789e-262c-659e70f945cb', 'branch:to:add_message', None)])\n"
     ]
    }
   ],
   "source": [
    "for checkpoint in checkpointer.list(config):\n",
    "    print(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d4aaee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "チェックポイントデータ：\n",
      "{'channel_values': {'messages': [SystemMessage(content='あなたは最小限の応答をする対話エージェントです。', additional_kwargs={}, response_metadata={}),\n",
      "                                 HumanMessage(content='私の好きなものはずんだ餅です。覚えておいてね。', additional_kwargs={}, response_metadata={}),\n",
      "                                 AIMessage(content='了解です。ずんだ餅が好きなんですね。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 48, 'total_tokens': 61, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'finish_reason': 'stop', 'logprobs': None}, id='run--29aa34cc-f491-4ada-a2a2-246a058e2091-0', usage_metadata={'input_tokens': 48, 'output_tokens': 13, 'total_tokens': 61}),\n",
      "                                 HumanMessage(content='私の好物は何か覚えてる？', additional_kwargs={}, response_metadata={}),\n",
      "                                 AIMessage(content='ずんだ餅です。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 80, 'total_tokens': 87, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'finish_reason': 'stop', 'logprobs': None}, id='run--816bd137-6c83-462b-92f8-844cbdee5c2a-0', usage_metadata={'input_tokens': 80, 'output_tokens': 7, 'total_tokens': 87})],\n",
      "                    'query': '私の好物は何か覚えてる？'},\n",
      " 'channel_versions': {'__start__': '00000000000000000000000000000006.0.24925599108332874',\n",
      "                      'branch:to:add_message': '00000000000000000000000000000007.0.9108803549024735',\n",
      "                      'branch:to:llm_response': '00000000000000000000000000000008.0.4414309472358884',\n",
      "                      'messages': '00000000000000000000000000000008.0.4414309472358884',\n",
      "                      'query': '00000000000000000000000000000006.0.24925599108332874'},\n",
      " 'id': '1f072c56-3998-6fee-8006-b12a2c39d3e1',\n",
      " 'ts': '2025-08-06T13:00:55.361731+00:00',\n",
      " 'v': 4,\n",
      " 'versions_seen': {'__input__': {},\n",
      "                   '__start__': {'__start__': '00000000000000000000000000000005.0.2501419612637731'},\n",
      "                   'add_message': {'branch:to:add_message': '00000000000000000000000000000006.0.24925599108332874'},\n",
      "                   'llm_response': {'branch:to:llm_response': '00000000000000000000000000000007.0.9108803549024735'}}}\n",
      "\n",
      "メタデータ：\n",
      "{'parents': {}, 'source': 'loop', 'step': 6}\n"
     ]
    }
   ],
   "source": [
    "print_checkpoint_dump(checkpointer, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c771dd7f",
   "metadata": {},
   "source": [
    "### Try other thread_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fd9358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': '私の好物は何？', 'messages': [SystemMessage(content='あなたは最小限の応答をする対話エージェントです。', additional_kwargs={}, response_metadata={}), HumanMessage(content='私の好物は何？', additional_kwargs={}, response_metadata={}), AIMessage(content='わかりません。あなたの好物は何ですか？', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 36, 'total_tokens': 50, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_ff25b2783a', 'finish_reason': 'stop', 'logprobs': None}, id='run--1b407575-e65c-42c1-88cf-8064dc5a6226-0', usage_metadata={'input_tokens': 36, 'output_tokens': 14, 'total_tokens': 50})]}\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"example-2\"}}\n",
    "user_query = State(query=\"私の好物は何？\")\n",
    "other_thread_response = compiled_graph.invoke(user_query, config)\n",
    "print(other_thread_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb20673d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "チェックポイントデータ：\n",
      "{'channel_values': {'messages': [SystemMessage(content='あなたは最小限の応答をする対話エージェントです。', additional_kwargs={}, response_metadata={}),\n",
      "                                 HumanMessage(content='私の好物は何？', additional_kwargs={}, response_metadata={}),\n",
      "                                 AIMessage(content='わかりません。あなたの好物は何ですか？', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 36, 'total_tokens': 50, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_ff25b2783a', 'finish_reason': 'stop', 'logprobs': None}, id='run--1b407575-e65c-42c1-88cf-8064dc5a6226-0', usage_metadata={'input_tokens': 36, 'output_tokens': 14, 'total_tokens': 50})],\n",
      "                    'query': '私の好物は何？'},\n",
      " 'channel_versions': {'__start__': '00000000000000000000000000000002.0.3650247078817699',\n",
      "                      'branch:to:add_message': '00000000000000000000000000000003.0.33873543303082465',\n",
      "                      'branch:to:llm_response': '00000000000000000000000000000004.0.8886753818001588',\n",
      "                      'messages': '00000000000000000000000000000004.0.8886753818001588',\n",
      "                      'query': '00000000000000000000000000000002.0.3650247078817699'},\n",
      " 'id': '1f072cca-a8ca-69d4-8002-5a5d8cfa6bc9',\n",
      " 'ts': '2025-08-06T13:53:00.872529+00:00',\n",
      " 'v': 4,\n",
      " 'versions_seen': {'__input__': {},\n",
      "                   '__start__': {'__start__': '00000000000000000000000000000001.0.3832440700888291'},\n",
      "                   'add_message': {'branch:to:add_message': '00000000000000000000000000000002.0.3650247078817699'},\n",
      "                   'llm_response': {'branch:to:llm_response': '00000000000000000000000000000003.0.33873543303082465'}}}\n",
      "\n",
      "メタデータ：\n",
      "{'parents': {}, 'source': 'loop', 'step': 2}\n"
     ]
    }
   ],
   "source": [
    "print_checkpoint_dump(checkpointer, config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent-py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
