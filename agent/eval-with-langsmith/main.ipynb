{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30cfad0e",
   "metadata": {},
   "source": [
    "# Chapter07: Evaluate RAG Application using LangSmith"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b761ebec",
   "metadata": {},
   "source": [
    "## 7.1 Generate Test Data and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e043a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "loaded = load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208c06de",
   "metadata": {},
   "source": [
    "### Load `LangChain` official documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db6bd80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import GitLoader\n",
    "\n",
    "def file_filter(file_path: str) -> bool:\n",
    "    return file_path.endswith(\".mdx\")\n",
    "\n",
    "loader = GitLoader(\n",
    "    clone_url=\"https://github.com/langchain-ai/langchain\",\n",
    "    repo_path=\"./langchain\",\n",
    "    branch=\"master\",\n",
    "    file_filter=file_filter,\n",
    ")\n",
    "\n",
    "documents = loader.load()[:400]\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4337c204",
   "metadata": {},
   "outputs": [],
   "source": [
    "for document in documents:\n",
    "    document.metadata[\"filename\"] = document.metadata[\"source\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c539927",
   "metadata": {},
   "source": [
    "### Generate test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bed801d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c208da17b74b709d64df975a06cf97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes:   0%|          | 0/1188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2af85cca075a404cbe1e6c378a8ec380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm=ChatOpenAI(model=\"gpt-4o\"),\n",
    "    critic_llm=ChatOpenAI(model=\"gpt-4o\"),\n",
    "    embeddings=OpenAIEmbeddings(),\n",
    ")\n",
    "\n",
    "testset = generator.generate_with_langchain_docs(\n",
    "    documents,\n",
    "    test_size=4,\n",
    "    distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d025f0dd",
   "metadata": {},
   "source": [
    "### Check the generated questions, contexts, and ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad0ca6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>metadata</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is NLP Cloud and how can it be set up for...</td>\n",
       "      <td>[# NLPCloud\\n\\n&gt;[NLP Cloud](https://docs.nlpcl...</td>\n",
       "      <td>NLP Cloud is an artificial intelligence platfo...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'docs/docs/integrations/providers/...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does Redis achieve low-latency reads and w...</td>\n",
       "      <td>[# Redis\\n\\n&gt;[Redis (Remote Dictionary Server)...</td>\n",
       "      <td>Redis achieves low-latency reads and writes by...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'docs/docs/integrations/providers/...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which lib simplifies API calls to Anthropic, A...</td>\n",
       "      <td>[# LiteLLM\\n\\n&gt;[LiteLLM](https://github.com/Be...</td>\n",
       "      <td>LiteLLM is a library that simplifies calling A...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'docs/docs/integrations/providers/...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does Clarifai use LLMs, embeddings, and ve...</td>\n",
       "      <td>[# Clarifai\\n\\n&gt;[Clarifai](https://clarifai.co...</td>\n",
       "      <td>Clarifai provides an AI platform that supports...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'docs/docs/integrations/providers/...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is NLP Cloud and how can it be set up for...   \n",
       "1  How does Redis achieve low-latency reads and w...   \n",
       "2  Which lib simplifies API calls to Anthropic, A...   \n",
       "3  How does Clarifai use LLMs, embeddings, and ve...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [# NLPCloud\\n\\n>[NLP Cloud](https://docs.nlpcl...   \n",
       "1  [# Redis\\n\\n>[Redis (Remote Dictionary Server)...   \n",
       "2  [# LiteLLM\\n\\n>[LiteLLM](https://github.com/Be...   \n",
       "3  [# Clarifai\\n\\n>[Clarifai](https://clarifai.co...   \n",
       "\n",
       "                                        ground_truth evolution_type  \\\n",
       "0  NLP Cloud is an artificial intelligence platfo...         simple   \n",
       "1  Redis achieves low-latency reads and writes by...         simple   \n",
       "2  LiteLLM is a library that simplifies calling A...      reasoning   \n",
       "3  Clarifai provides an AI platform that supports...  multi_context   \n",
       "\n",
       "                                            metadata  episode_done  \n",
       "0  [{'source': 'docs/docs/integrations/providers/...          True  \n",
       "1  [{'source': 'docs/docs/integrations/providers/...          True  \n",
       "2  [{'source': 'docs/docs/integrations/providers/...          True  \n",
       "3  [{'source': 'docs/docs/integrations/providers/...          True  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ef5e64",
   "metadata": {},
   "source": [
    "### Store the generated dataset into LangSmith Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb11cdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "dataset_name = \"agent-book\"\n",
    "\n",
    "client = Client()\n",
    "\n",
    "if client.has_dataset(dataset_name=dataset_name):\n",
    "    client.delete_dataset(dataset_name=dataset_name)\n",
    "\n",
    "dataset = client.create_dataset(dataset_name=dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01f5ec78",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "outputs = []\n",
    "metadatas = []\n",
    "\n",
    "for testset_record in testset.test_data:\n",
    "    inputs.append(\n",
    "        {\n",
    "            \"question\": testset_record.question,\n",
    "        }\n",
    "    )\n",
    "    outputs.append(\n",
    "        {\n",
    "            \"contexts\": testset_record.contexts,\n",
    "            \"ground_truth\": testset_record.ground_truth,\n",
    "        }\n",
    "    )\n",
    "    metadatas.append(\n",
    "        {\n",
    "            \"source\": testset_record.metadata[0][\"source\"],\n",
    "            \"evolution_type\": testset_record.evolution_type,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e55ff275",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.create_examples(\n",
    "    inputs=inputs,\n",
    "    outputs=outputs,\n",
    "    metadata=metadatas,\n",
    "    dataset_id=dataset.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7245de6",
   "metadata": {},
   "source": [
    "### Set evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebb51f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_core.language_models import BaseChatModel\n",
    "from langsmith.schemas import Example, Run\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.metrics.base import Metric, MetricWithEmbeddings, MetricWithLLM\n",
    "\n",
    "class RagasMetricEvaluator:\n",
    "    def __init__(self, metric: Metric, llm: BaseChatModel, embeddings: Embeddings):\n",
    "        self.metric = metric\n",
    "\n",
    "        # Set the `embedding model` and `llm` to evaluate\n",
    "        if isinstance(self.metric, MetricWithLLM):\n",
    "            self.metric.llm = LangchainLLMWrapper(llm)\n",
    "        if isinstance(self.metric, MetricWithEmbeddings):\n",
    "            self.metric.embeddings = LangchainEmbeddingsWrapper(embeddings)\n",
    "\n",
    "    def evaluate(self, run: Run, example: Example) -> dict[str, Any]:\n",
    "        context_strs = [doc.page_content for doc in run.outputs[\"contexts\"]]\n",
    "\n",
    "        score = self.metric.score(\n",
    "            {\n",
    "                \"question\": example.inputs[\"question\"], # user's query\n",
    "                \"answer\": run.outputs[\"answer\"],    # actual answer\n",
    "                \"contexts\": context_strs,   # actual retrieved results\n",
    "                \"ground_truth\": example.outputs[\"ground_truth\"] # expected answer\n",
    "            }\n",
    "        )\n",
    "\n",
    "        return {\"key\": self.metric.name, \"score\": score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68b9c1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from ragas.metrics import answer_relevancy, context_precision\n",
    "\n",
    "metrics = [context_precision, answer_relevancy]\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "evaluators = [RagasMetricEvaluator(metric, llm, embeddings).evaluate for metric in metrics]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db2a044",
   "metadata": {},
   "source": [
    "### Instantiate retriever to retrieve relevant documents from `LangChain Official Documents`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f16cf65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "db = Chroma.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3e0ba31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template('''\\\n",
    "以下の文脈だけを踏まえて質問に回答してください。\n",
    "\n",
    "文脈：\"\"\"\n",
    "{context}\n",
    "\"\"\"\n",
    "                                          \n",
    "質問：{question}\n",
    "''')\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "chain = RunnableParallel(\n",
    "    {\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"context\": retriever,\n",
    "    }\n",
    ").assign(answer=prompt | model | StrOutputParser())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60603e03",
   "metadata": {},
   "source": [
    "### Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2715b4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(inputs: dict[str, Any]) -> dict[str, Any]:\n",
    "    question = inputs[\"question\"]\n",
    "    output = chain.invoke(question)\n",
    "    return {\n",
    "        \"contexts\": output[\"context\"],\n",
    "        \"answer\": output[\"answer\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39916dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'back-order-70' at:\n",
      "https://smith.langchain.com/o/28cc992d-1e18-4f1c-932a-48fc88779125/datasets/e7d9536f-ed98-4c25-915a-d3dce4fc4a50/compare?selectedSessions=4484f38e-09ef-432b-942b-2769007df622\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f032418c13bb4bf2af956848aad2b856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.contexts</th>\n",
       "      <th>outputs.answer</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.contexts</th>\n",
       "      <th>reference.ground_truth</th>\n",
       "      <th>feedback.context_precision</th>\n",
       "      <th>feedback.answer_relevancy</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which lib simplifies API calls to Anthropic, A...</td>\n",
       "      <td>[page_content='# LiteLLM\\n\\n&gt;[LiteLLM](https:/...</td>\n",
       "      <td>The library that simplifies API calls to Anthr...</td>\n",
       "      <td>None</td>\n",
       "      <td>[# LiteLLM\\n\\n&gt;[LiteLLM](https://github.com/Be...</td>\n",
       "      <td>LiteLLM is a library that simplifies calling A...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.964720</td>\n",
       "      <td>1.516522</td>\n",
       "      <td>3461a14d-8b07-4c8f-9817-e9d0dff77688</td>\n",
       "      <td>3ce47dc7-9435-44d3-a454-3cdf67c876c3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does Redis achieve low-latency reads and w...</td>\n",
       "      <td>[page_content='# Redis\\n\\n&gt;[Redis (Remote Dict...</td>\n",
       "      <td>Redis achieves low-latency reads and writes pr...</td>\n",
       "      <td>None</td>\n",
       "      <td>[# Redis\\n\\n&gt;[Redis (Remote Dictionary Server)...</td>\n",
       "      <td>Redis achieves low-latency reads and writes by...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.482042</td>\n",
       "      <td>1e076068-6150-4781-ad26-c1bf2a2e6227</td>\n",
       "      <td>3224b6d4-dddf-404e-b784-97e00b0f4614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is NLP Cloud and how can it be set up for...</td>\n",
       "      <td>[page_content='# NLPCloud\\n\\n&gt;[NLP Cloud](http...</td>\n",
       "      <td>NLP Cloud is an artificial intelligence platfo...</td>\n",
       "      <td>None</td>\n",
       "      <td>[# NLPCloud\\n\\n&gt;[NLP Cloud](https://docs.nlpcl...</td>\n",
       "      <td>NLP Cloud is an artificial intelligence platfo...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.911899</td>\n",
       "      <td>3.422051</td>\n",
       "      <td>0e8c91dd-e17f-42a1-bd97-70f17b6fb9e6</td>\n",
       "      <td>867ec346-b4b4-4aab-92d6-124f9ccd2a4c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does Clarifai use LLMs, embeddings, and ve...</td>\n",
       "      <td>[page_content='# Clarifai\\n\\n&gt;[Clarifai](https...</td>\n",
       "      <td>Clarifai provides a comprehensive AI platform ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[# Clarifai\\n\\n&gt;[Clarifai](https://clarifai.co...</td>\n",
       "      <td>Clarifai provides an AI platform that supports...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.533796</td>\n",
       "      <td>6.144896</td>\n",
       "      <td>890b6cad-1177-4778-aaf6-984087c5c5af</td>\n",
       "      <td>74194e22-2e91-4a89-a116-fa3dc4f720ac</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults back-order-70>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "evaluate(\n",
    "    predict,\n",
    "    data=\"agent-book\",\n",
    "    evaluators=evaluators,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577e15ee",
   "metadata": {},
   "source": [
    "## 7.2 Good or Bad Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b66fc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import UUID\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from langsmith import Client\n",
    "\n",
    "def display_feedback_buttons(run_id: UUID) -> None:\n",
    "    # Prepare the `good` botton and `bad` botton\n",
    "    good_button = widgets.Button(\n",
    "        description=\"Good\",\n",
    "        button_style=\"success\",\n",
    "        icon=\"thumbs-up\",\n",
    "    )\n",
    "    bad_button = widgets.Button(\n",
    "        description=\"Bad\",\n",
    "        button_style=\"danger\",\n",
    "        icon=\"thumbs-down\",\n",
    "    )\n",
    "\n",
    "    def on_button_clicked(button: widgets.Button) -> None:\n",
    "        if button == good_button:\n",
    "            score = 1\n",
    "        elif button == bad_button:\n",
    "            score = 0\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown button: {button}\")\n",
    "        \n",
    "        client = Client()\n",
    "        client.create_feedback(run_id=run_id, key=\"thumbs\", score=score)\n",
    "        print(\"Send the feedback.\")\n",
    "    \n",
    "    good_button.on_click(on_button_clicked)\n",
    "    bad_button.on_click(on_button_clicked)\n",
    "\n",
    "    # Display the buttons\n",
    "    display(good_button, bad_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ebf5a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChainは、大規模言語モデル（LLMs）を活用したアプリケーションを開発するためのフレームワークです。LangChainは、LLMアプリケーションのライフサイクルの各段階を簡素化することを目的としています。具体的には、以下のような機能を提供しています：\n",
      "\n",
      "1. **開発**: LangChainのオープンソースコンポーネントやサードパーティの統合を利用してアプリケーションを構築できます。また、LangGraphを使用して、ストリーミングや人間の介入をサポートする状態保持エージェントを構築できます。\n",
      "\n",
      "2. **プロダクション化**: LangSmithを使用してアプリケーションを検査、監視、評価し、継続的に最適化して自信を持ってデプロイできます。\n",
      "\n",
      "3. **デプロイメント**: LangGraph Platformを使用して、LangGraphアプリケーションをプロダクション対応のAPIやアシスタントに変換できます。\n",
      "\n",
      "LangChainは、LLMsや関連技術（埋め込みモデルやベクトルストアなど）の標準インターフェースを実装し、数百のプロバイダーと統合しています。これにより、開発者はプロバイダー間での切り替えが容易になり、複数のコンポーネントを組み合わせた複雑なアプリケーションの構築が可能になります。また、LangChainは観測性と評価の機能を提供し、アプリケーションのモニタリングや最適化を支援します。\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3ef4151af3840dc94e051adb0db0e2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Good', icon='thumbs-up', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f358e59d5541fa8ead73bb977f2922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='danger', description='Bad', icon='thumbs-down', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_core.tracers.context import collect_runs\n",
    "\n",
    "# `collect_runs` is used to get the LangSmith's trace Run ID\n",
    "with collect_runs() as runs_cb:\n",
    "    output = chain.invoke(\"LangChainの概要を教えて\")\n",
    "    print(output[\"answer\"])\n",
    "    run_id = runs_cb.traced_runs[0].id\n",
    "\n",
    "display_feedback_buttons(run_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-agent-py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
